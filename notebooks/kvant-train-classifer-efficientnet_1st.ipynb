{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7526248,"sourceType":"datasetVersion","datasetId":4308295},{"sourceId":8133613,"sourceType":"datasetVersion","datasetId":4793447,"isSourceIdPinned":true},{"sourceId":8134851,"sourceType":"datasetVersion","datasetId":4808680},{"sourceId":6127,"sourceType":"modelInstanceVersion","modelInstanceId":4598}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train Notebook is based on Keras 3.0 with TF\n\n\n- tensorflow-2.15.0\n- keras_cv-0.8.1\n- keras-3.0.4\n","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/kerasv3-lib-ds/keras_cv-0.8.2-py3-none-any.whl --no-deps\n\n!pip install -q /kaggle/input/kerasv3-lib-ds/tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps\n\n!pip install -q /kaggle/input/kerasv3-lib-ds/keras-3.0.4-py3-none-any.whl --no-deps","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:24:47.241162Z","iopub.execute_input":"2024-04-16T07:24:47.241526Z","iopub.status.idle":"2024-04-16T07:25:55.136977Z","shell.execute_reply.started":"2024-04-16T07:24:47.241496Z","shell.execute_reply":"2024-04-16T07:25:55.135662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # you can also use jax, tensorflow or torch\n\n\nimport keras_cv\nimport keras\n#from tensorflow import keras\nfrom keras import ops\nimport tensorflow as tf\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\n\nimport joblib\nimport shutil\nimport json\n\nimport matplotlib.pyplot as plt \n\n\nimport sys\nimport platform\n\n\nimport matplotlib.pyplot as plt\nimport scipy\nimport joblib\nfrom scipy.signal import spectrogram\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T07:25:55.139423Z","iopub.execute_input":"2024-04-16T07:25:55.139957Z","iopub.status.idle":"2024-04-16T07:26:14.037599Z","shell.execute_reply.started":"2024-04-16T07:25:55.139922Z","shell.execute_reply":"2024-04-16T07:26:14.036668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"–û–°: \", platform.system())\nprint(\"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: \", platform.machine())\nprint(\"–í–µ—Ä—Å–∏—è Python: \", sys.version_info)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.038705Z","iopub.execute_input":"2024-04-16T07:26:14.039189Z","iopub.status.idle":"2024-04-16T07:26:14.043938Z","shell.execute_reply.started":"2024-04-16T07:26:14.039164Z","shell.execute_reply":"2024-04-16T07:26:14.043014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\ntry:\n    print(keras.__version__)\nexcept:\n    print('Tf.Keras')\nprint(keras_cv.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.046817Z","iopub.execute_input":"2024-04-16T07:26:14.047215Z","iopub.status.idle":"2024-04-16T07:26:14.118454Z","shell.execute_reply.started":"2024-04-16T07:26:14.047182Z","shell.execute_reply":"2024-04-16T07:26:14.117575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('TPU active')\nexcept ValueError:\n    tpu = None\n    print('TPU non active')\n\n# –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    gpus = tf.config.list_physical_devices('GPU')\n    print(gpus)\n    if gpus:\n        try:\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n        except RuntimeError as e:\n            print(e)\n            \n    if len(gpus) >= 2:\n        strategy = tf.distribute.MirroredStrategy()\n    else:\n        strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)\nprint(tf.config.list_physical_devices())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.119450Z","iopub.execute_input":"2024-04-16T07:26:14.119735Z","iopub.status.idle":"2024-04-16T07:26:14.542639Z","shell.execute_reply.started":"2024-04-16T07:26:14.119712Z","shell.execute_reply":"2024-04-16T07:26:14.541603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    \n    DEV = \"TPU\" if tpu else \"GPU\"\n    if tpu:\n        CACHE=True\n        CACHE_DIR=\"\"\n    else:\n        CACHE=False\n        CACHE_DIR=\"\"\n        \n    VERSION = 1\n    DF_VERSION = 1\n    MIX = 1 # USE MIXED PRECISION\n    SEED = 42\n    IMAGE_SIZE = (128, 128) \n    BATCH_SIZE = 256* strategy.num_replicas_in_sync\n    EPOCHS = 20\n    EARLY_STOPPING = 4 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö —á–µ—Ä–µ–∑ –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞–¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n    LR_MODE = 'cos' #'exp' , 'step' - —Ä–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω–º—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è\n    \n    CLASS_NAMES = ['BrassMono-BoldItalic', \n                   'GhastlyPanicCyr', \n                   'ambidexter_regular',\n                   'GaneshaType-Regular', \n                   'AlumniSansCollegiateOne-Italic',\n                   'AlumniSansCollegiateOne-Regular', \n                   'BrassMono-Italic',\n                   'better-vcr-5.2', \n                   'ArefRuqaaInk-Bold', \n                   'Aguante-Regular',\n                   'BrassMono-Bold', \n                   'ArefRuqaaInk-Regular', \n                   'Realest-Extended',\n                   'BrassMono-Regular', \n                   'TanaUncialSP']\n    LABEL2NAME = dict(enumerate(CLASS_NAMES))\n    NAME2LABEL = {v:k for k, v in LABEL2NAME.items()}\n    NUM_CLASSES = len(CLASS_NAMES)\n    AUTOTUNE = tf.data.AUTOTUNE\n    PRESET = 'efficientnetv2_b2_imagenet'   #'efficientnetv2_b2_imagenet','efficientnetv2_s_imagenet', 'efficientnetv2_b0_imagenet_classifier'\n                                    #\"yolo_v8_l_backbone_coco\", \"yolo_v8_m_backbone_coco\"# Name of pretrained MODEL\n                                    #\"densenet121_imagenet\"\n                                    #\"csp_darknet_l\", \"csp_darknet_l_imagenet\"\n                                    #\"vitdet_large_sa1b\"\n    fold = 2 # Which fold to set as validation data\n    VERBOSE = 1  # Verbosity\n    LR_START, LR_MAX, LR_MIN = 5e-5, 1e-4 , 1e-6\n    DATASET_DIR = '/kaggle/input/kvant-fonts-ds'\n\nCFG = Config()\nkeras.utils.set_random_seed(seed=CFG.SEED)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.545009Z","iopub.execute_input":"2024-04-16T07:26:14.545335Z","iopub.status.idle":"2024-04-16T07:26:14.555563Z","shell.execute_reply.started":"2024-04-16T07:26:14.545310Z","shell.execute_reply":"2024-04-16T07:26:14.554531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MIXED PRECISION\n\nif CFG.MIX:\n    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n    print('Mixed precision enabled')\nelse:\n    print('Using full precision')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.556687Z","iopub.execute_input":"2024-04-16T07:26:14.557057Z","iopub.status.idle":"2024-04-16T07:26:14.572038Z","shell.execute_reply.started":"2024-04-16T07:26:14.557026Z","shell.execute_reply":"2024-04-16T07:26:14.571175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read dataset","metadata":{}},{"cell_type":"code","source":"# –ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å\n\nroot_dir = CFG.DATASET_DIR\ndata = []\n\n# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–∞–ø–∫–∞–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –∫–∞—Ç–∞–ª–æ–≥–µ\nfor font_name in os.listdir(root_dir):\n    font_dir = os.path.join(root_dir, font_name)\n    \n    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–∞–ø–∫–∞–º –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ —à—Ä–∏—Ñ—Ç–∞\n    for image_type in os.listdir(font_dir):\n        image_dir = os.path.join(font_dir, image_type)\n        \n        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n        for file in os.listdir(image_dir):\n            file_path = os.path.join(image_dir, file)\n            \n            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å–ø–∏—Å–æ–∫\n            data.append([font_name, image_type, file_path])\n\n# –°–æ–∑–¥–∞–µ–º DataFrame\ndf = pd.DataFrame(data, columns=['font_name', 'image_type', 'path'])","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:14.573158Z","iopub.execute_input":"2024-04-16T07:26:14.573432Z","iopub.status.idle":"2024-04-16T07:26:45.139600Z","shell.execute_reply.started":"2024-04-16T07:26:14.573409Z","shell.execute_reply":"2024-04-16T07:26:45.138774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:45.140808Z","iopub.execute_input":"2024-04-16T07:26:45.141081Z","iopub.status.idle":"2024-04-16T07:26:45.161378Z","shell.execute_reply.started":"2024-04-16T07:26:45.141058Z","shell.execute_reply":"2024-04-16T07:26:45.160228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['font_name'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:45.165757Z","iopub.execute_input":"2024-04-16T07:26:45.166337Z","iopub.status.idle":"2024-04-16T07:26:45.232156Z","shell.execute_reply.started":"2024-04-16T07:26:45.166299Z","shell.execute_reply":"2024-04-16T07:26:45.231369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.NAME2LABEL, CFG.LABEL2NAME, CFG.NUM_CLASSES","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:45.233175Z","iopub.execute_input":"2024-04-16T07:26:45.233427Z","iopub.status.idle":"2024-04-16T07:26:45.521148Z","shell.execute_reply.started":"2024-04-16T07:26:45.233405Z","shell.execute_reply":"2024-04-16T07:26:45.520223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['class_label'] = df.font_name.map(CFG.NAME2LABEL)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:26:45.522214Z","iopub.execute_input":"2024-04-16T07:26:45.522516Z","iopub.status.idle":"2024-04-16T07:26:45.596679Z","shell.execute_reply.started":"2024-04-16T07:26:45.522492Z","shell.execute_reply":"2024-04-16T07:26:45.595927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InversionLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(InversionLayer, self).__init__(**kwargs)\n\n    def call(self, data, training=None):\n        if training:\n            data[\"images\"] = 1.0 - data[\"images\"]\n        return data\n    \n\ndef build_augmenter(dim=CFG.IMAGE_SIZE):\n    augmenters = [\n        #RandAugment —Ç–æ–ª—å–∫–æ –¥–ª—è 3—Ö –∫–∞–Ω–∞–ª–æ–≤\n        keras_cv.layers.RandAugment(value_range=(0, 1), augmentations_per_image=1, magnitude=0.1,input_shape=(None, 128, 128, 1)),\n        keras_cv.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n        #keras_cv.layers.MixUp(alpha=2.0),\n        keras_cv.layers.RandomCutout(height_factor=(0.2, 0.5), width_factor=(0.3, 0.6)), \n        keras_cv.layers.RandomShear(\n                                        x_factor=0.2,\n                                        y_factor=0.4,\n                                        interpolation=\"bilinear\",\n                                        fill_mode=\"reflect\",\n                                        fill_value=0.3,\n                                        bounding_box_format=None,\n                                        seed=CFG.SEED\n                                    ),\n        InversionLayer() # –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–π –∏–Ω–≤–µ—Ä—Å–∏–∏\n    ]\n    \n    def augment(img, label):\n        data = {\"images\":img, \"labels\":label}\n        for augmenter in augmenters:\n            if tf.random.uniform([]) < 0.2:\n                data = augmenter(data, training=True)\n        return data[\"images\"], data[\"labels\"]\n    \n    return augment\n\n\ndef build_decoder(with_labels=True, \n                  target_size=CFG.IMAGE_SIZE, \n                  dtype=32, \n                ):\n    \n    def decode_img(path):\n        file_bytes = tf.io.read_file(path)\n        image = tf.io.decode_png(file_bytes, channels=1, dtype=tf.uint8)\n        image = tf.image.resize(image, CFG.IMAGE_SIZE, method=\"bilinear\")\n        image = tf.cast(image, tf.float32) / 255.0\n        \n        # Mono channel to 3 channels to use \"ImageNet\" weights\n        #tf.print(image.shape)\n        image = tf.tile(image, [1, 1, 3])\n        \n        return image\n\n\n        \n\n\n    def decode_label(label):\n        label = tf.one_hot(label, CFG.NUM_CLASSES)\n        label = tf.cast(label, tf.float32)\n        label = tf.reshape(label, [CFG.NUM_CLASSES])\n        return label\n    \n    def decode_with_labels(path, label=None):\n        img = decode_img(path)\n        label = decode_label(label)\n        return (img, label)\n    \n    return decode_with_labels if with_labels else decode_img\n\n\ndef build_dataset( \n                  paths, \n                  labels=None, \n                  batch_size=32, \n                  cache=True,\n                  decode_fn=None,\n                  augment_fn=None,\n                  augment=False, \n                  repeat=True, \n                  shuffle=1024, \n                  cache_dir=\"\", \n                  drop_remainder=False):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter()\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = (paths) if labels is None else (paths, labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.SEED)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:41:26.080491Z","iopub.execute_input":"2024-04-16T07:41:26.080845Z","iopub.status.idle":"2024-04-16T07:41:26.102607Z","shell.execute_reply.started":"2024-04-16T07:41:26.080816Z","shell.execute_reply":"2024-04-16T07:41:26.101716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üî™ | Data Split\n\nIn the following code snippet, the data is divided into `5` folds. Note that, the `groups` argument is used to prevent any overlap of patients between the training and validation sets, thus avoiding potential **data leakage** issues. Additionally, each split is stratified based on the `class_label`, ensuring a uniform distribution of class labels in each fold.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.SEED)\n\ndf[\"fold\"] = -1\ndf.reset_index(drop=True, inplace=True)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(df, y=df[\"class_label\"])):\n    df.loc[valid_idx, \"fold\"] = fold\ndf.groupby([\"fold\", \"font_name\"])[[\"path\"]].count()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:41:26.920676Z","iopub.execute_input":"2024-04-16T07:41:26.920989Z","iopub.status.idle":"2024-04-16T07:41:27.155000Z","shell.execute_reply.started":"2024-04-16T07:41:26.920963Z","shell.execute_reply":"2024-04-16T07:41:27.154056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É –∏ –æ—Å–∏\nfig, axs = plt.subplots(5, 1, figsize=(10, 20))\n\n# –î–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Å—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É\nfor fold in range(5):\n    # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã\n    subset = df[df[\"fold\"] == fold]\n    \n    # –°—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É\n    sns.countplot(data=subset, x=\"class_label\", ax=axs[fold])\n    \n    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫\n    axs[fold].set_title(f\"Fold {fold}\")\n    \n# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–∏–∫\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:41:27.281325Z","iopub.execute_input":"2024-04-16T07:41:27.281598Z","iopub.status.idle":"2024-04-16T07:41:28.808065Z","shell.execute_reply.started":"2024-04-16T07:41:27.281577Z","shell.execute_reply":"2024-04-16T07:41:28.807145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:41:28.809623Z","iopub.execute_input":"2024-04-16T07:41:28.809923Z","iopub.status.idle":"2024-04-16T07:41:28.822203Z","shell.execute_reply.started":"2024-04-16T07:41:28.809898Z","shell.execute_reply":"2024-04-16T07:41:28.821330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample from  data\nsample_df = df.sample(frac=1).reset_index(drop=True)\ntrain_df = sample_df[sample_df.fold != CFG.fold]\nvalid_df = sample_df[sample_df.fold == CFG.fold]\nprint(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n\n# Train\ntrain_paths = train_df.path.values\ntrain_labels = train_df.class_label.values\n\ntrain_ds = build_dataset(paths=train_paths,  \n                         labels=train_labels,\n                         batch_size=CFG.BATCH_SIZE,\n                         repeat=True, \n                         shuffle=True, \n                         augment=False, \n                         cache=False,\n                         #cache_dir=CFG.CACHE_DIR\n                        )\n\n# Valid\nvalid_paths = valid_df.path.values\nvalid_labels = valid_df.class_label.values\n\nvalid_ds = build_dataset(paths=valid_paths,  \n                         labels=valid_labels,\n                         batch_size=CFG.BATCH_SIZE,\n                         repeat=None, \n                         shuffle=None, \n                         augment=None, \n                         cache=False,\n                         #cache_dir=CFG.CACHE_DIR\n                        )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:44:51.274853Z","iopub.execute_input":"2024-04-16T07:44:51.275477Z","iopub.status.idle":"2024-04-16T07:44:51.760094Z","shell.execute_reply.started":"2024-04-16T07:44:51.275446Z","shell.execute_reply":"2024-04-16T07:44:51.759321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimgs, tars = next(iter(train_ds))\nprint(imgs.shape)\nSIZE = imgs.shape[1:]\nmin_value = np.min(imgs)\nmax_value = np.max(imgs)\nprint(\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –º–∞—Ç—Ä–∏—Ü–µ: \", min_value)\nprint(\"Maximal –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –º–∞—Ç—Ä–∏—Ü–µ: \", max_value)\nnum_imgs = CFG.BATCH_SIZE\nplt.figure(figsize=(4*4, num_imgs//4*5))\nfor i in range(num_imgs):\n    plt.subplot(num_imgs//4, 4, i + 1)\n    img = imgs[i].numpy()[...,0]  # Adjust as per your image data format\n    tar = CFG.LABEL2NAME[np.argmax(tars[i].numpy())]\n    plt.imshow(img, cmap='gray')\n    plt.title(f\"Target: {tar}\")\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:44:57.187044Z","iopub.execute_input":"2024-04-16T07:44:57.187942Z","iopub.status.idle":"2024-04-16T07:45:58.446981Z","shell.execute_reply.started":"2024-04-16T07:44:57.187908Z","shell.execute_reply":"2024-04-16T07:45:58.443905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üîç | Loss & Metric¬∂\n\nThe evaluation metric in this competition is KL Divergence, defined as,\n\nD\nKL\n(\nP\n‚à•\nQ\n)\n=\n‚àë\ni\n \nP\n(\ni\n)\nlog\n(\nP\n(\ni\n)\nQ\n(\ni\n)\n)\n \nWhere:\n\nP\n  is the true distribution.\nQ\n  is the predicted distribution.\nInterestingly, as KL Divergence is differentiable, we can directly use it as our loss function. Thus, we don't need to use a third-party metric like Accuracy to evaluate our model. Therefore, valid_loss can stand alone as an indicator for our evaluation. In keras, we already have impelementation for KL Divergence loss so we only need to import it.","metadata":{}},{"cell_type":"code","source":"LOSS = tf.keras.losses.KLDivergence()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:28.307314Z","iopub.execute_input":"2024-04-16T07:04:28.307919Z","iopub.status.idle":"2024-04-16T07:04:28.313515Z","shell.execute_reply.started":"2024-04-16T07:04:28.307885Z","shell.execute_reply":"2024-04-16T07:04:28.311659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ü§ñ | Modeling¬∂\n\nThis notebook uses the EfficientNetV2 B2 from KerasCV's collection of pretrained models. To explore other models, simply modify the preset in the CFG (config). Check the KerasCV website for a list of available pretrained models.","metadata":{}},{"cell_type":"code","source":"def build_model():\n    # Detect hardware, return appropriate distribution strategy\n    \n    with strategy.scope():\n        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n        inputs = keras.Input(shape=(128, 128, 1))\n\n        # –°–ª–æ–π 1\n        x = keras.layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n        # –°–ª–æ–π 2\n        x = keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n        # –°–ª–æ–π 3\n        x = keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        # –°–ª–æ–π 4\n        x = keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n        x = keras.layers.BatchNormalization()(x)\n\n        # –°–ª–æ–π 5\n        x = keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n        x = keras.layers.BatchNormalization()(x)\n        gap = keras.layers.GlobalAveragePooling2D()\n        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏\n        x = gap(x)\n        x = keras.layers.Dense(4096, activation='relu')(x)\n        x = keras.layers.Dropout(0.5)(x)\n        x = keras.layers.Dense(4096, activation='relu')(x)\n        x = keras.layers.Dropout(0.5)(x)\n        outputs = keras.layers.Dense(CFG.NUM_CLASSES, activation='softmax', name= 'outputs')(x)  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —É –≤–∞—Å 1000 –∫–ª–∞—Å—Å–æ–≤\n\n        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n        model = keras.Model(inputs=inputs, outputs=outputs)\n\n        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n        \n    return model\n\nmodel = build_model()\n# Model Sumamry\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:28.315163Z","iopub.execute_input":"2024-04-16T07:04:28.315943Z","iopub.status.idle":"2024-04-16T07:04:28.603961Z","shell.execute_reply.started":"2024-04-16T07:04:28.315911Z","shell.execute_reply":"2024-04-16T07:04:28.603023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    with strategy.scope():\n\n        #backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xl_backbone_coco\")\n        model = keras_cv.models.ImageClassifier.from_preset(\n        \n            CFG.PRESET,\n            #pooling=\"avg\", \n            #activation=\"softmax\",\n            num_classes=CFG.NUM_CLASSES  \n        )\n\n        # Compile the model  \n        model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n                      loss='categorical_crossentropy', \n                      metrics=['accuracy']\n                     )\n    return model\nmodel = build_model()\n# Model Sumamry\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:28.605166Z","iopub.execute_input":"2024-04-16T07:04:28.605457Z","iopub.status.idle":"2024-04-16T07:04:36.697613Z","shell.execute_reply.started":"2024-04-16T07:04:28.605431Z","shell.execute_reply":"2024-04-16T07:04:36.696648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early stopping round","metadata":{}},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=CFG.EARLY_STOPPING,\n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.698985Z","iopub.execute_input":"2024-04-16T07:04:36.699300Z","iopub.status.idle":"2024-04-16T07:04:36.704229Z","shell.execute_reply.started":"2024-04-16T07:04:36.699273Z","shell.execute_reply":"2024-04-16T07:04:36.703117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚öì | LR Schedule\nA well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.\n\n- lr_ramp_ep: –≠—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö, –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –æ—Ç lr_start –¥–æ lr_max. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –º–µ–¥–ª–µ–Ω–Ω–æ ‚Äú—Ä–∞–∑–æ–≥—Ä–µ–≤–∞—Ç—å—Å—è‚Äù –ø–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ –ø–µ—Ä–µ–π—Ç–∏ –∫ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è.\n- lr_sus_ep: –≠—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö, –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ lr_max. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ ‚Äú—É—Å—Ç–æ—è—Ç—å—Å—è‚Äù –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ –Ω–∞—á–∞—Ç—å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ.\n- lr_decay: –≠—Ç–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä–æ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ ‚Äú–ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è‚Äù. –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ–Ω—å—à–µ 1 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –±—É–¥–µ—Ç —É–º–µ–Ω—å—à–∞—Ç—å—Å—è —Å –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–æ–π.\n- lr_start: –≠—Ç–æ –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ, —Å –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è ‚Äú—Ä–∞–∑–æ–≥—Ä–µ–≤‚Äù —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è.\n- lr_max: –≠—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ ‚Äú—Ä–∞–∑–æ–≥—Ä–µ–≤–∞‚Äù. –ü–æ—Å–ª–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è, —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ª–∏–±–æ –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∞ —ç—Ç–æ–º —É—Ä–æ–≤–Ω–µ –≤ —Ç–µ—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö (lr_sus_ep), –ª–∏–±–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –∑–∞—Ç—É—Ö–∞—Ç—å.\n- lr_min: –≠—Ç–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∑–∞—Ç—É—Ö–∞–Ω–∏—è. –≠—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ, –∫ –∫–æ—Ç–æ—Ä–æ–º—É —Å—Ç—Ä–µ–º–∏—Ç—Å—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ ‚Äú—Ä–∞–∑–æ–≥—Ä–µ–≤–∞‚Äù –∏ ‚Äú–ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è‚Äù.","metadata":{}},{"cell_type":"code","source":"import math\n\n\ndef get_lr_callback(batch_size=CFG.BATCH_SIZE, \n                    mode='cos', \n                    epochs=CFG.EPOCHS, \n                    plot=False, \n                    lr_start = CFG.LR_START, \n                    lr_max = CFG.LR_MAX, \n                    lr_min = CFG.LR_MIN):\n\n    #lr_start, lr_max, lr_min = 1e-5, 6e-5 , 1e-7 #2e-6 * batch_size\n    lr_ramp_ep, lr_sus_ep, lr_decay = epochs//5, 1, 0.1\n    \n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.705447Z","iopub.execute_input":"2024-04-16T07:04:36.705809Z","iopub.status.idle":"2024-04-16T07:04:36.719900Z","shell.execute_reply.started":"2024-04-16T07:04:36.705783Z","shell.execute_reply":"2024-04-16T07:04:36.719005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.BATCH_SIZE, mode=CFG.LR_MODE, plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.721170Z","iopub.execute_input":"2024-04-16T07:04:36.721597Z","iopub.status.idle":"2024-04-16T07:04:36.949434Z","shell.execute_reply.started":"2024-04-16T07:04:36.721563Z","shell.execute_reply":"2024-04-16T07:04:36.948522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üíæ | Model Checkpointing & CSV logger","metadata":{}},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(f\"/kaggle/working/best_model.keras\",\n                                         monitor='val_loss',\n                                         save_best_only=True,\n                                         save_weights_only=False,\n                                         mode='min')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.951094Z","iopub.execute_input":"2024-04-16T07:04:36.951456Z","iopub.status.idle":"2024-04-16T07:04:36.956171Z","shell.execute_reply.started":"2024-04-16T07:04:36.951422Z","shell.execute_reply":"2024-04-16T07:04:36.955305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = keras.callbacks.CSVLogger('training_log.csv', separator=',', append=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.957345Z","iopub.execute_input":"2024-04-16T07:04:36.957767Z","iopub.status.idle":"2024-04-16T07:04:36.965642Z","shell.execute_reply.started":"2024-04-16T07:04:36.957736Z","shell.execute_reply":"2024-04-16T07:04:36.964753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    history = model.fit(\n        train_ds, \n        epochs=CFG.EPOCHS,\n        callbacks=[\n            lr_cb, \n            ckpt_cb, \n            csv_logger,\n            early_stopping\n        ], \n        steps_per_epoch=len(train_df)//CFG.BATCH_SIZE,\n        validation_data=valid_ds, \n        verbose=CFG.VERBOSE\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:04:36.966884Z","iopub.execute_input":"2024-04-16T07:04:36.967433Z","iopub.status.idle":"2024-04-16T07:13:13.893904Z","shell.execute_reply.started":"2024-04-16T07:04:36.967394Z","shell.execute_reply":"2024-04-16T07:13:13.892190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# |Results of train","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:13:13.895283Z","iopub.status.idle":"2024-04-16T07:13:13.896345Z","shell.execute_reply.started":"2024-04-16T07:13:13.896089Z","shell.execute_reply":"2024-04-16T07:13:13.896111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_epoch = np.argmin(history.history['val_loss'])\nbest_loss = history.history['val_loss'][best_epoch]\nbest_acc = history.history['val_accuracy'][best_epoch]\n\nprint(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST Acc   : {best_acc:.3f}\\n>>>> BEST Epoch : {best_epoch}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T07:13:13.897498Z","iopub.status.idle":"2024-04-16T07:13:13.897968Z","shell.execute_reply.started":"2024-04-16T07:13:13.897733Z","shell.execute_reply":"2024-04-16T07:13:13.897755Z"},"trusted":true},"execution_count":null,"outputs":[]}]}